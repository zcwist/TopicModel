For me, the most obvious connection between the three modes of thinking we read about is that each demands the actor to constantly stop and evaluate their progress. We need to step back and understand why something might be working better that we thought it would, or what question is actually being asked, or what components are a porotype are actually necessary for and MVP. Being able to step back and evaluate also requires data, and each of these three approaches require data to move forward.
The differences are most subtle. I think design thinking puts starts with a question and puts the user at the middle while positive deviance is more about understanding why something is working. Neither of those two have a clear step-by-step process, which is required for hypothesis driven entrepreneurship.
In my consulting experience, we often tried to come up with a hypothesis to give us a place to start. I think it is useful as long as you know enough about the situation. The same was true when we’d say we were going to use design thinking – it was only useful if we really took time to get out and understand a problem by talking to the people close to it. Often, consulting engagements don’t lend themselves to that kind of pacing. The closest I ever came to using positive variance was benchmarking. We’d get data to tell a client how they stacked up against those in their industry or those who were leading the way.
For our engagement with REDF, I think I’d really like to stretch myself to use more design thinking. I’d love to talk to some of the social enterprises to see if public procurement really was a pain point for them. I also think if there are any that have been especially successful in that space we could learn a lot. Same goes for really successful certification programs – meaning low cost and well respected. Our professors are already driving us to have a hypothesis, so I think the framework provided in the article will be useful as we start to drill down on that.  